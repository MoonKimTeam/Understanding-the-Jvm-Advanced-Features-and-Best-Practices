# ch 05. 최적화 사례분석 및 실전

## 사례 분석

### 대용량 메모리 기기 대상 배포 전략

- 문제 상황: 일일 PV 15만, JDK 5, 4 코어 제온, 16GB 메모리, 64비트 Centos 5.4, Resin(웹서버), 힙 12GB에서 서버 실행 효율 저하, 응답 지연 발생
    - 패러렐 컬렉터(패러렐 스캐빈지 + 패러렐 올드) 사용
    - 패러렐 컬렉터는 일시 정지 시간보다 처리량에 중점을 둔 컬렉터
    - 웹 페이지 직렬화 과정에서 구세대에 거대 객체가 쌓임 -> 힙을 12GB나 준비해두어도 금세 가득 참
    - 전에는 힙이 1.5GB에 불과했고, 32비트 운영체제 였고 웹사이트가 느리긴 했지만 10초 이상 답이 없는 경우는 없었음
        - 간단히 힙 크기를 1.5GB로 줄이기만 해도 해결 가능. 비싼 하드웨어 구매에 낭비
- 해결책: 일시 정지 시간에 민감하고 대용량 메모리를 갖추고 있음 -> 셰넌도어나 ZGC처럼 지연 시간통제를 목표로 하는 가비지 컬렉터 이용
    - 패러렐 컬렉터로도 큰 힙을 관리할 수 있는 방법: 전체 GC 없이 하루 이상 가동 될수 있도록 만들어 두고 매일 새벽에 전체 GC를 수행하거나 애플리케이션 서버를 자동으로 재시작 하도록 스케쥴링
- 전체 GC 빈도를 제어하려면 오래 생존하는 객체가 적어야 함
- 웹 애플리케이션에서 대다수 객체는 요청이나 페이지 범위를 넘어서 생존 금지
    - 세션, 전역 수준으로 오래 살아 남는 객체는 매우 적어야 함
- 긴 일시 정지는 G1 컬렉터(ZGC)의 등장과 점진적 회복 사용으로 많이 줆
- 64비트 VM 성능은 32비트 보다 조금 느림
- 애플리케이션이 충분히 안정적이어야 함(힙 메모리 오버플로 시 스냅숏 생성 불가능하므로)
- 64비트 VM이 32보다 포인터 확장, 데이터 타입 정렬, 패딩 등의 요인 때문에 메모리 더 사용(압축 포인터 사용으로 해결)
- 위 문제들 때문에 VM 여러 개로 논리 클러스터 구축하기도 함
    - 같은 물리 머신에서 여러 애플리케이션 서버 프로세스 띄우고 다른 포트 할당
    - 로드 밸런서를 두고 리버스 프록시 방식으로 요청 분배
- 반대로, 물리 머신 `한 대`에서 논리 클러스터 구축하는 목적은 하드웨어 자원을 최대한 끌어 쓰기 위함(고가용성 요구 사항 불필요)
    - 부하의 완벽 균등 분산이 불필요하므로 선호도(affinity) 클러스터로도 충분
- 논리적 클러스터 구성의 단점
    - 노드들이 전역 자원(디스크 등) 놓고 경합
    - 자원 풀(연결 풀) 등을 효율적으로 활용 어려움
    - 클러스터 노드로 32비트 가상 머신을 이용한다면 노드별 메모리 여전히 32비트로 제한
    - 해시 맵이나 키-값 캐시 등의 로컬 캐시를 많이 이용하는 애플리케이션이라면 논리 클러스터 방식에서는 상당량의 메모리가 낭비됨(캐시를 노드당 하나씩 두기 때문)
        - 중앙화한 캐시를 활용하기
- 실제 적용한 해결책: 32비트 가상 머신 다섯 개로 논리 클러스터 구축, 각각 메모리 2GB(힙 1.5GB), 아파치로 부하 분산
    - 페이지 기반 웹사이트는 디스크, 메모리 접근 시간이 중요하고 프로세서는 덜 중요 -> CMS 컬렉터로 변경

### 클러스터간 동기화로 인한 메모리 오버플로

- 문제 상황: 듀얼 프로세서, 8GB 메모리, HP 미니 컴퓨터 2대, 웹로직 9.2 3개씩 총 6개 노드로 클러스터 구성
    - 공유 데이터를 DB로 관리했지만 읽기, 쓰기 잦고 경합 치열해서 성능 영향 큼
    - JBossCache 글로벌 캐시 구축 -> 처음에는 원활했다, 시간이 지나서 메모리 오버플로 간헐척 발생
    - OOM 힙 덤프 스냅숏을 보면 org.jgroups.protocols.pbcast.NAKACK 발견
    - JBossCache는 클러스터 사이 통신에 JGroups 개념 이용
    - JGroups는 데이터 패킷을 보내고 받는데 필요한 다양한 필수 특성을 자유롭게 조합할 수 있는 프로토콜 스택 이용
        - 데이터 전송 성공을 보장하기 위해(실패 시 재전송 위해) 모든 노드가 데이터를 제대로 수신했는지 확인할 때까지 메모리에 보관해야 함
        - 이 시스템의 필터는 여러 머신에 동시 로그인을 막기 위해 필터는 요청이 수신될 때마다 마지막 작업 시간을 갱신하고 그 시간을 모든 노드에 동기화
        - 이 필터가 클러스터 노드 간의 네트워크 통신 빈번하게 유발, 특정 상황에서 다 처리 못하면 데이터가 메모리에 쌓이다가 오버플로 발생
- 해결책: 이 경우 JBossCache와 시스템 구현 방식에 모두 결함 -> 후속 버전에서 개선
- JBossCache 같은 분산 클러스터 캐시를 동기화에 이용하면 네트워크 통신이 자주 일어남 -> 네트워크 동기화 너무 자주 하지 말아야

### 힙 메모리 부족으로 인한 오버플로 오류

- 문제 상황: CometD 1.1.1, 제티 7.14, 인텔 코어 i5 CPU, 4GB 메모리, 32비트 윈도우
    - 메모리 오버플로가 가끔 발생
    - 힙메모리를 최대로 늘리려고 했지만 실패
    - OOM 시 덤프 파일 생성도 못함
- 해결책: 운영체제의 개별 프로세스가 관리 가능한 메모리 최대 크기 존재
    - 다이렉트 메모리는 힙에 속하지 않아 프로세스 메모리의 힙을 제외한 부분에 할당
    - 다이렉트 메모리도 GC 대상이지만 공간 부족 시 GC에 알리 지 못함 -> 구세대가 꽉차서 GC 발생해야 GC 가능
    - CometD 1.1.1 프레임워크는 다이렉트 메모리를 이용하는 NIO 연산을 매우 많이 수행
    - 물리 메모리 용량이 적은 시스템이나 애플리케이션에서 많이 차지하는 영역들
        - 다이렉트 메모리: -XX:MaxDirectMemorySize로 조절 가능. 부족시 OOM.
        - 스레드 스택: -Xss로 조절 가능. 부족시 SOE(StackOverflowException).
        - 소켓 버퍼 영역(Receive, Send 영역): 소켓 연결 많은 경우 중요. 부족 시 IOException: Too many Open files.
        - JNI 코드: 네이티브 라이브러리 이용 시 호출. 힙이 아니라 JVM의 네이티브 메서드 스택과 네이티브 메모리 사용
        - 가상머신과 가비지 컬렉터

### 시스템을 느려지게 하는 외부 명령어

- 문제 상황: 프로세서 4개, 솔라리스 10, 글래스피시
    - 동시성 스트레스 테스트에서 응답 속도가 지나치게 느림
    - 프로세서 이용률이 높았으나, 이 시스템이 소비하는 것이 아니었음
    - fork 시스템 콜(프로세스 생성 시 호출)이 자원 대부분을 소비
- 해결책: 시스템 정보가 필요해서 요청 시 외부 셸 스크립트를 실행하도록 함
    - Runtime.getRuntime().exec() 메서드로 실행 -> 자원을 매우 많이 소비
- 외부 명령은 빠르게 실행되더라도 프로세스 생성 비용 간과해선 안 됨

### 서버 가상 머신 프로세스 비정상 종료

- 문제 상황: 듀얼 프로세서, 8GB 메모리, HP 미니 컴퓨터 2대, 웹로직 9.2 3대로 총 6노드 클러스터
    - 한동안 문제 없다 클러스터 노드의 가상 머신 프로세스가 갑자기 닫히는 일 빈번해짐
    - 프로세스가 hs_err_pid###.log 파일만 남기고 사라짐
    - 두 미니 컴퓨터의 모든 노드에서 프로세스 들이 충돌
    - 최근 사무 자동화 포털 연동 -> 이 경영 정보 시스템에서 할 일 상태가 바뀌면 포털 시스템이 웹 서비스를 통해 받아와 동기화 하는 식
    - 동기화 요청 시 최대 3분이 되어서야 응답. 그마저도 모두 타임아웃으로 인한 연결 중단이었음
    - 할 일 항목이 수시로 변경되므로 웹서비스 호출을 비동기 수행 -> 대기 중인 스레드와 소켓 연결이 점점 많아짐
    - 결국 가상 머신 한계 넘어서 가상 머신 프로세스가 비정상 종료됨
- 해결책: 연동 인터페이스를 수정해서 비동기 호출 부분을 생산자/소비자 방식의 메시지 큐로 변경

### 부적절한 데이터 구조로 인한 메모리 과소비

- 문제 상황: 64비트 JVM 이용 백그라운드 RPC 서버, -Xms4g -Xmx8g -Xmn1g 설정, 파뉴+CMS 컬렉터
    - 마이너 GC 시간 30ms 이내
    - but, 데이터 분석 위해 10분 단위로 80MB 크기 파일을 메모리로 읽어들여야 했음 -> 100만 개 이상의 HashMap<Long, Long> 객체 만듦
    - 마이너 GC가 100만 개 넘는 객체 검사하느라 일시 저지가 500밀리초로 늘어남
    - 로그 상에서 GC 시간은 대체로 매우 짧았음
    - but,데이터 파일 분석 시 총 800MB 용량의 에덴이 빠르게 채워져서 가비지 컬렉션 일어나고 GC 후에도 신세대 객체 대부분 살아있음
    - 파뉴 컬렉터가 많은 생존 객체를 생존자 객체로 복사하면서 가비지 컬렉션 시간이 급격히 늘어남
- 해결책: 생존자 공간을 제거 -> 마이너 GC 후 곧바로 구세대 이동(부작용 큼)
    - 올바른 해법: 프로그램 수정 - 현재 해시맵 공간 효율성을 구체적으로 계산해보면 매우 비효율적임

### 윈도우 가상 메모리로 인한 긴 일시 정지

- 문제 상황: 서드 파티 서비스로부터 15초마다 얻어옴
    - 데스크톱용이어서 메모리가 많이 필요하지 않았지만 GC가 원인
    - 대체로 100ms 이내 종료, 그러나 가끔씩 1분 이상 진행
    - 창을 최소화하면 메모리 사용량이 급격히 줄어드나 가상 메모리는 변하지 않음
    - 최소화하면 작업 메모리가 디스크로 스왑됨
    - 이 상태에서 가비지 컬렉션하려면 스왑된 데이터를 메모리로 다시 불러와야함
- 해결책: -Dsun.awt.keepWorkingSetOnMinimize=true 매개 변수를 추가

### 안전 지점으로 인한 긴 일시 정지

- 문제 상황: 비교적 큰 HBase 클러스터, JDK 8, G1 컬렉터
    - 매일 같이 맵리듀스 ,스파크 오프라인 분석
    - 지연 시간은 중요하지 않아 -XX:MaxGCPauseMillis는 500ms로 넉넉하게 설정
    - 하지만 일정 기간 운영 후 3초까지 길어지는 일 자주 발생, but 회수 실제 시간은 단 수백 ms
- 해결책: 로그 분석 후 원인 파악
    - -XX:+PrintSafepointStatistics와 -XX:PrintSafepointStatistics Count=1으로 안전지점에서의 통계 로그 출력
    - 스레드 두 개가 특히 느려서 장기간 공회전하며 대기 중
    - -XX:+SafepoiM7imeout과 -XX:SafepointTimeoutDelay=2000 매개 변수 추가 후 원인이 되는 스레드 발견(Threads which did not reach the
      safepoint)
    - 어떤 요인이 이 스레드가 안전지점에 진입하는 걸 막고 있음
    - `"안전 지점은 프로그램을 장시간 실행하는 특성이 있는가?"라는 원칙에 기초하여 선택` -> 메서드 호출, 순환문 점프, 비정상적인 점프 모두 안전 지점 될수 있음
    - 핫스팟 VM은 안전 지점이 너무 많아지지 않게 하기 위해서 최적화
        - int나 범위가 좁은 데이터 타입을 루프 변수로 사용하면(카운티드 루프) 기본적으로 안전지점으로 설정되지 않음
        - long 처럼 큰 데이터 타입을 루프변수로 사용하는 순환문을 언카운티드 루프라고 함
        - but, 반복 횟수만이 반복문 실행 시간 결정 요인은 아님. 너무 길다면 카운티드 루프일지라도 오래 걸림
        - 최종 해결책: 루프 변수 타입을 long으로 변경

## 실전: 이클립스 구동 시간 줄이기

### 최적화 전 상태

### JDK 버전 업그레이드에 따른 성능 변화

### 클래스 로딩 시간 최적화

### 컴파일 시간 최적화

### 메모리 설정 최적화

### 적절한 컬렉터 선택으로 지연 시간 단축




